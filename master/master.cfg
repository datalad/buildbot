# -*- python -*-
# ex: set syntax=python:

from buildbot.plugins import *
from buildbot.process.properties import Interpolate

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Global settings (might migrate into local_setup later)
master_url = "http://smaug.datalad.org:8010/"

gh_org_git = "https://github.com/datalad"
gh_datalad_git = gh_org_git + "/datalad.git"

slave_port = 9989

# Some settings to get directly to c right away

c['title'] = "DataLad"
c['titleURL'] = "http://datalad.org"

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server (usually the html.WebStatus page) is visible. This
# typically uses the port number set in the Waterfall 'status' entry, but
# with an externally-visible host name which the buildbot cannot figure out
# without some help.

c['buildbotURL'] = "http://smaug.datalad.org:8020/"

# must be 0.9. .version is not descriptive -- reports "latest" in 0.8
is_buildbot_09 = hasattr(buildslave, "DockerLatentBuildSlave")
c['db'] = {'db_url': "sqlite:///state.sqlite", }

# This is a sample buildmaster config file. It must be installed as
# 'master.cfg' in your buildmaster's base directory.

# Apparently buildbot has issue with having .'s in the names, thus replacing
# dots with __

env = {}; execfile('private/slaves.py', {}, env)
slaves = env['slaves']


####### BUILDSLAVES

from commands import getstatusoutput
def start_local_docker(name, image):
    """Checks if a container based on the image already running, if not starts it detached
    """
    s, out = getstatusoutput("docker ps | grep ' %s '" % image)
    if not (len(out) and not s):
        # must be not running already, let's start
        s_, out_ = getstatusoutput("docker run -d '%s' > ids/%s.id" % (image, name))
        if not s_:
            print "%s started successfully" % image
        else:
            print "%s failed to start with exit code %d: %s" % (image, s_, out_)

c['slaves'] = []
for name, info in slaves.iteritems():
    if info['type'] == 'docker':
        docker_image = 'datalad_pymvpa/buildbot:slave-docker-dl-%s' % info['docker_base'].replace('.', '_')
        if is_buildbot_09:
            slave = buildslave.DockerLatentBuildSlave(
                name, info['password'],
                docker_host=info['docker_service'], # local_setup.docker_host,
                image=docker_image)
        else:
            # Regular slave we should bring up outside
            slave = buildslave.BuildSlave(
                name, info['password'])
            # but we should start it ourselves
            start_local_docker(name, docker_image)
    elif info['type'] in ['virtualbox', 'native']:
        # Regular slave instance
        slave = buildslave.BuildSlave(
            name, info['password'])
    else:
        raise ValueError("Unknown type of a beast: %(type)s" % info)

    c['slaves'].append(slave)

c['protocols'] = {'pb': {'port': slave_port}}

######## CHANGESOURCES
# yoh: replaced with a hook
#
#c['change_source'] = []
#c['change_source'].append(changes.GitPoller(
#        gh_datalad_git,
#        workdir='gitpoller-workdir', branch='master',
#        pollinterval=300))
#

####### BUILDERS

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which slaves can execute them.  Note that any particular build will
# only take place on one slave.

def datalad_test_steps(platform=None, version=None):
    test_env = {
       'DATALAD_LOG_LEVEL': 'INFO',
       # Workaround for https://github.com/GrahamDumpleton/wrapt/issues/98
       'WRAPT_DISABLE_EXTENSIONS': '1',
    }

    # We have to setup virtualenv where we would "install" datalad for
    # in-place development.  That would generate necessary scripts for the
    # entry points
    venv_dir = "venv-ci"
    # Madness to overcome the fact that on Windows bin/ is Scripts/
    path_suffix = ''
    if platform == 'Windows':
        # Use upstairs directory to not get punished by path length limits
        test_env['DATALAD_TESTS_TEMP_DIR'] = r"C:\tmp"
        #test_env['DATALAD_TESTS_KEEPTEMP'] = "1"
        bin_dir = "Scripts"
        path_sep = ";"
        dir_sep = "\\"
    else:
        bin_dir = "bin"
        path_sep = ":"
        dir_sep = "/"
    if platform == "OSX":
        # lzma is installed under /usr/local/bin and pip install pyliblzma
        # does not fail but then lzma module is not importable
        # https://github.com/datalad/datalad/issues/1979
        path_suffix = '/usr/local/bin:'
    bin_path = dir_sep.join(["%(prop:workdir)s", 'build', venv_dir, bin_dir])
    test_env['PATH'] = Interpolate("%s%s%s${PATH}" % (bin_path, path_sep, path_suffix))
    # to speed up pip
    pip_env = test_env.copy()
    if platform == 'Debian':
	    pip_env['http_proxy'] = pip_env['https_proxy'] = 'http://10.0.42.1:3128'

    # There is some genuine screw up on wheezy that even with pip installed nose
    # python -m nose sees system-wide installed one.  So we will instruct
    # to use nosetests there -- should be installed
    nosetests_cmd = ["nosetests"] \
                    if platform == 'Debian' and version.startswith("7.") \
                    else ["python", "-c", "import nose; nose.main()"]

    custom_prepip_cmds = ["setuptools==33.1.1"] \
                    if platform == 'Ubuntu' and version == "14.04" else []

    test_steps = [
        # TODO -- cook up datalad.wtf()
        steps.ShellCommand(
            command=["git-annex", "version"]),
        steps.ShellCommand(
            command=["git", "--version"]),
        steps.ShellCommand(
            command=["virtualenv", "--clear", "--system-site-packages", venv_dir],
            name="virtualenv %s" % venv_dir,
            haltOnFailure=True),
        # some bots, e.g. nd70 might have too old pip -- upgrade
        # and having old urllib3 breaks pip install on nd80 from https:// of github
        # pysocks is needed for a recent urllib3, bleh
        # And pip for some reason installs 1.9.1 whl even though we are asking for >=1.11
        # see https://github.com/datalad/datalad/pull/475#issuecomment-223029121
	# So I will just remove it here explicitly  to mitigate
        steps.ShellCommand(
            command=["rm", "-f", "lib/python-wheels/urllib3-1.9.1-py2.py3-none-any.whl"],
            haltOnFailure=False),
        steps.ShellCommand(
            command=["pip", "install", "pip>=8", "urllib3>=1.11", "pysocks", 
                     # until https://github.com/GrahamDumpleton/wrapt/issues/98 is fixed
                     #"git+https://github.com/yarikoptic/wrapt@develop"
                    ] + custom_prepip_cmds,
            name="pip install pip>=8 etc",
            env=pip_env,
            haltOnFailure=True),
        steps.ShellCommand(
            command=["rm", "-f", "lib/python-wheels/urllib3-1.9.1-py2.py3-none-any.whl"],
            haltOnFailure=False),
        # on OSX box apparently --system-site adds only system-wide paths, not
        # user's which is where we installed all necessary depends.  So let's
        # be simple and greedy and install everything necessary
        steps.ShellCommand(
            command=["pip", "install", "-r", "requirements.txt"],
            name="pip install",
            env=pip_env),
        steps.ShellCommand(
            # causes problems on OSX with tricky git-based version
            # command=["python", "setup.py", "develop"],
            # name="develop install",
            command=["pip", "install", "-e", "."],
            name="pip install -e .",
            env=test_env),
        steps.ShellCommand(
            command=nosetests_cmd + ["-s", "-v", "datalad"],
            name="nosetests", description="testing", descriptionDone="tests done",
            env=test_env),
    #    steps.ShellCommand(command=["nosetests", "-v", "datalad/tests/test_cmd.py"])
    ]

    # Didn't work as expected, so not enabled for now
    if False: # platform != "Windows":
        test_steps += [
            steps.ShellCommand(
                command=["make", "test", "MODULE=datalad.tests.test_installed"],
                name="test 'make test'"
            ),
        ]
    return test_steps


def datalad_factory(branch='master', deb=False, platform=None, version=None):
    factory = util.BuildFactory()

    factory.addSteps([
        steps.Git(
            haltOnFailure = True,
            logEnviron = False,
            repourl=gh_datalad_git,
            branch=branch,
            mode='full',  # 'full' for PRs I believe ;-)
            #method = 'clone', #'copy',
            codebase='datalad',
            submodules=True,
            retry=(5, 3)
        )] +
        datalad_test_steps(platform=platform, version=version))
    return factory

def datalad_builders(name_prefix, slaves, category=None):
    return [
        util.BuilderConfig(name="%s-%s" % (name_prefix, slave),
            slavenames=[slave],
            category=category,
            factory=datalad_factory(platform=slave_opts['OS'],
                                    version=slave_opts.get('version')))
        for slave, slave_opts in slaves.iteritems()
    ] # for now there is no "equivalent" slaves, thus just give all slaves


c['builders'] = datalad_builders("datalad-tests", slaves)


####### SCHEDULERS

datalad_codebases = {
    'datalad': {
            'repository': gh_datalad_git,
            'branch': None,
            'revision': None,
            'trusted_logins': ['yarikoptic', 'hanke', 'bpoldrack', 'debanjum', 'glalteva', 'mih'],
            },
}

# reverse map (little to no clue -- just going after ethereum setup ;) -- 
# primarily for looking forward when we would get multiple repositories etc)
all_repositories = dict([(e['repository'],r) for r, e in datalad_codebases.iteritems()])

# Codebase generator
def codebaseGenerator(chdict):
    return all_repositories[chdict['repository']]

c['codebaseGenerator'] = codebaseGenerator


# Configure the Schedulers, which decide how to react to incoming changes.  In this
# case, just kick off a 'runtests' build
code_builder_names = [str(b.name) for b in c['builders']]
c['schedulers'] = [
    schedulers.SingleBranchScheduler(
                            name="datalad-master",
                            change_filter=util.ChangeFilter(project='datalad', branch='master'),
                            codebases=datalad_codebases,
                            treeStableTimer=None,
                            builderNames=code_builder_names),
    schedulers.ForceScheduler(
                            name="datalad-forced",
                            codebases=datalad_codebases.keys(),
                            builderNames=code_builder_names)
]

#### PULL REQUESTS

c['schedulers'] += [
    # Pull requests
    schedulers.AnyBranchScheduler(
        name="datalad-pr",
        change_filter=util.ChangeFilter(project='datalad', category='pull-request'),
        codebases=datalad_codebases,
        treeStableTimer=60,
        builderNames=['datalad-pr-%s' % slave for slave in slaves.keys()]
        )
]


c['builders'] += datalad_builders("datalad-pr", slaves, category='pull-request')


####### STATUS TARGETS

# 'status' is a list of Status Targets. The results of each build will be
# pushed to these targets. buildbot/status/*.py has a variety to choose from,
# including web pages, email senders, and IRC bots.

c['status'] = []

if is_buildbot_09:
    # minimalistic config to activate new web UI
    c['www'] = dict(port=8020, plugins=dict(waterfall_view={}, console_view={}))
else:
    import json
    from buildbot.status import html
    from buildbot.status.web import auth, authz
    from buildbot.status.github import GitHubStatus
    from buildbot.process.properties import Interpolate
    from buildstatusimage import BuildStatusImageResource

    # Load users from external file, see users.json.sample
    users = []
    for user in json.load(open("private/users.json")):
        # yoh: had to adjust for read unicode
        users.append((user['username'].encode(), user['password'].encode()))

    authz_cfg=authz.Authz(
        # change any of these to True to enable; see the manual for more
        # options
        auth=auth.BasicAuth(users),
        gracefulShutdown = False,
        forceBuild = 'auth', # use this to test your slave once it is set up
        forceAllBuilds = 'auth',
        pingBuilder = 'auth',
        stopBuild = 'auth',
        stopAllBuilds = 'auth',
        cancelPendingBuild = 'auth',
    )

    class WebStatus(html.WebStatus):
        def setupUsualPages(self, numbuilds, num_events, num_events_max):
            html.WebStatus.setupUsualPages(self, numbuilds, num_events, num_events_max)
            self.putChild("buildstatusimage", BuildStatusImageResource())

    # Customize handler to limit testing PRs only if submitted
    # by "trustworthy" fellas
    from buildbot.status.web.hooks.github import GitHubEventHandler
    from twisted.python import log

    class RestrictedGitHubEventHandler(GitHubEventHandler):
        """Decorated GitHubEventHandler to limit PRs to only a specified set of pushers
        """
        def __init__(self, *args, **kwargs):
            #    TODO would n't work if not hardcode atm  because options/args are hardcoded
            #    as they are passed in getChanges.  Need to patch if I see this one
            #    working as destined
            self._trusted_logins = kwargs.pop('trusted_logins', datalad_codebases['datalad']['trusted_logins'])
            super(RestrictedGitHubEventHandler, self).__init__(*args, **kwargs)

        def _is_trusted_user(self, login):
            return login in self._trusted_logins

        def handle_pull_request(self, payload):
            # for some reason 'pusher' is absent for some PRs... may
            # be when automatically updated for new/rewritten commits?
            login = payload['pull_request']['user']['login']
            #with open("/tmp/payload.txt", 'w') as f:
            #    json.dump(payload, f, indent=True)

            if payload['action'] == 'labeled':
                if self._is_trusted_user(payload['sender']['login']) \
                   and payload['label']['name'] == 'buildbot':
                    log.msg("Allowing testing of this PR state because it was labeled with 'buildbot' label")
                    payload['action'] = 'synchronize' # cheat checks
                else:
                    return ([], 'git')
            elif self._trusted_logins and not self._is_trusted_user(login):
                log.msg("Ignoring pull request action %s made by %s since (s)he "
                        "is not listed among trusted_logins" % (payload['action'], login))
                return ([], 'git')
            return super(RestrictedGitHubEventHandler, self).handle_pull_request(payload)

    tokens = json.load(open("private/tokens.json"))
    c['status'].append(WebStatus(
        #        http_port = "ssl:port=8443:privateKey=/etc/ssl/server.key"
        #                    ":certKey=/etc/ssl/server.crt:extraCertChain=/etc/ssl/server.ca-bundle",
        http_port = 8020,
        authz=authz_cfg,
        change_hook_auth=["file:private/changehook.passwd"],
        change_hook_dialects={'github': {
            'class': RestrictedGitHubEventHandler,
            # not in effect atm:
            'trusted_logins': datalad_codebases['datalad']['trusted_logins'],
            'token': tokens['datalad']["token"],
            }},
        order_console_by_time=True))

    # GitHub Status
    for repo in tokens:
        gs = GitHubStatus(
            token=tokens[repo]["token"],
            repoOwner=tokens[repo]["owner"],
            repoName=repo,
            sha=Interpolate("%(src:"+repo+":revision)s"),
            startDescription='DEV build started.',
            endDescription='DEV build done.')
        c['status'].append(gs)

# IRC bot
from buildbot.status import words

ircbot = json.load(open("private/ircbot.json"))

import yaml # nasty hack to overcome "everything unicode but buildbot doesn't like it"
ircbot = yaml.load(json.dumps(ircbot))

c['status'].append(words.IRC(host=ircbot['server'],
                             nick=ircbot['nickname'],
                             password=ircbot['password'],
                             channels=ircbot['channels'],
                             notify_events={
                                'successToException': 1,
                                'successToFailure': 1,
                                'failureToSuccess': 1,
                                'exceptionToSuccess': 1}))
